{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fa9998-ac9a-4f8d-ae05-3684e32db8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d3758dd-6133-4d12-8973-78a429f2df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_per_user(data, train_size=0.8, target_column='stress'):\n",
    "    users = list(set(data.id))\n",
    "    users = sorted(users, reverse=True)\n",
    "    total_users = len(users)\n",
    "    slice_idx = int(train_size * total_users)\n",
    "    users_train = users[:slice_idx]\n",
    "    users_test = users[slice_idx:]\n",
    "\n",
    "    # Split data based on user IDs\n",
    "    train_data = data[data.id.isin(users_train)]\n",
    "    test_data = data[data.id.isin(users_test)]\n",
    "\n",
    "    x_train = train_data.drop(['id', target_column], axis=1)\n",
    "    y_train = train_data[target_column]\n",
    "    x_test = test_data.drop(['id', target_column], axis=1)\n",
    "    y_test = test_data[target_column]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c4ad6a-bdd8-4eb2-a69a-575964397cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33106f20-f77c-4387-8758-25d084a37859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EDA_0</th>\n",
       "      <th>EDA_1</th>\n",
       "      <th>EDA_2</th>\n",
       "      <th>EDA_3</th>\n",
       "      <th>TEMP_0</th>\n",
       "      <th>TEMP_1</th>\n",
       "      <th>TEMP_2</th>\n",
       "      <th>TEMP_3</th>\n",
       "      <th>ACC1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>BVP_55</th>\n",
       "      <th>BVP_56</th>\n",
       "      <th>BVP_57</th>\n",
       "      <th>BVP_58</th>\n",
       "      <th>BVP_59</th>\n",
       "      <th>BVP_60</th>\n",
       "      <th>BVP_61</th>\n",
       "      <th>BVP_62</th>\n",
       "      <th>BVP_63</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5452.450365</td>\n",
       "      <td>5366.846848</td>\n",
       "      <td>5264.122627</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>126.326243</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.371386</td>\n",
       "      <td>-124.493001</td>\n",
       "      <td>-136.216532</td>\n",
       "      <td>-137.408002</td>\n",
       "      <td>-128.387507</td>\n",
       "      <td>-111.782506</td>\n",
       "      <td>-91.536409</td>\n",
       "      <td>-71.450360</td>\n",
       "      <td>-54.013997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5264.122627</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>5127.156998</td>\n",
       "      <td>5013.021944</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>90.734562</td>\n",
       "      <td>...</td>\n",
       "      <td>40.556707</td>\n",
       "      <td>36.106477</td>\n",
       "      <td>30.326959</td>\n",
       "      <td>25.850055</td>\n",
       "      <td>23.818332</td>\n",
       "      <td>23.653838</td>\n",
       "      <td>23.849453</td>\n",
       "      <td>23.195923</td>\n",
       "      <td>21.515416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5127.156998</td>\n",
       "      <td>5013.021944</td>\n",
       "      <td>5372.556718</td>\n",
       "      <td>5235.591090</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>-27.904372</td>\n",
       "      <td>...</td>\n",
       "      <td>59.620226</td>\n",
       "      <td>48.839201</td>\n",
       "      <td>38.658357</td>\n",
       "      <td>31.562887</td>\n",
       "      <td>28.882079</td>\n",
       "      <td>28.415272</td>\n",
       "      <td>27.312718</td>\n",
       "      <td>22.711332</td>\n",
       "      <td>13.432982</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5372.556718</td>\n",
       "      <td>5235.591090</td>\n",
       "      <td>5184.228979</td>\n",
       "      <td>5155.692989</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>-27.904372</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.892373</td>\n",
       "      <td>-97.182554</td>\n",
       "      <td>-94.319469</td>\n",
       "      <td>-83.391734</td>\n",
       "      <td>-65.897576</td>\n",
       "      <td>-45.375840</td>\n",
       "      <td>-26.334550</td>\n",
       "      <td>-12.494826</td>\n",
       "      <td>-5.474934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5184.228979</td>\n",
       "      <td>5155.692989</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>5081.504758</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>-39.768266</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.795332</td>\n",
       "      <td>-4.105633</td>\n",
       "      <td>-2.803019</td>\n",
       "      <td>-2.358440</td>\n",
       "      <td>-2.225067</td>\n",
       "      <td>-2.042790</td>\n",
       "      <td>-1.833838</td>\n",
       "      <td>-1.958320</td>\n",
       "      <td>-2.878597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78761</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1146.439053</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>13.827887</td>\n",
       "      <td>13.207938</td>\n",
       "      <td>12.701858</td>\n",
       "      <td>12.233733</td>\n",
       "      <td>11.664393</td>\n",
       "      <td>10.917924</td>\n",
       "      <td>9.918415</td>\n",
       "      <td>8.640562</td>\n",
       "      <td>7.097016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78762</th>\n",
       "      <td>17</td>\n",
       "      <td>-1146.439053</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.632268</td>\n",
       "      <td>-26.405514</td>\n",
       "      <td>-23.444943</td>\n",
       "      <td>-20.092160</td>\n",
       "      <td>-16.562248</td>\n",
       "      <td>-12.918468</td>\n",
       "      <td>-9.186125</td>\n",
       "      <td>-5.339913</td>\n",
       "      <td>-1.519005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78763</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448817</td>\n",
       "      <td>12.195777</td>\n",
       "      <td>11.816217</td>\n",
       "      <td>11.322788</td>\n",
       "      <td>10.753448</td>\n",
       "      <td>10.146151</td>\n",
       "      <td>9.526202</td>\n",
       "      <td>8.868298</td>\n",
       "      <td>8.045917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78764</th>\n",
       "      <td>17</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.110212</td>\n",
       "      <td>-7.427495</td>\n",
       "      <td>-5.491737</td>\n",
       "      <td>-3.189070</td>\n",
       "      <td>-0.544800</td>\n",
       "      <td>2.213339</td>\n",
       "      <td>4.908218</td>\n",
       "      <td>7.350056</td>\n",
       "      <td>9.450290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78765</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>4.212357</td>\n",
       "      <td>3.010416</td>\n",
       "      <td>1.618694</td>\n",
       "      <td>0.125757</td>\n",
       "      <td>-1.379833</td>\n",
       "      <td>-2.860118</td>\n",
       "      <td>-4.340404</td>\n",
       "      <td>-5.833341</td>\n",
       "      <td>-7.402191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78766 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        EDA_0        EDA_1        EDA_2        EDA_3        TEMP_0  \\\n",
       "0       2  5452.450365  5366.846848  5264.122627  5115.746165  10279.722091   \n",
       "1       2  5264.122627  5115.746165  5127.156998  5013.021944  10279.722091   \n",
       "2       2  5127.156998  5013.021944  5372.556718  5235.591090  10279.722091   \n",
       "3       2  5372.556718  5235.591090  5184.228979  5155.692989  10279.722091   \n",
       "4       2  5184.228979  5155.692989  5115.746165  5081.504758  10464.748540   \n",
       "...    ..          ...          ...          ...          ...           ...   \n",
       "78761  17 -1141.515991 -1141.515991 -1146.439053 -1141.515991 -11412.917628   \n",
       "78762  17 -1146.439053 -1141.515991 -1141.515991 -1141.515991 -11802.683112   \n",
       "78763  17 -1141.515991 -1141.515991 -1136.589079 -1151.365964 -11802.683112   \n",
       "78764  17 -1136.589079 -1151.365964 -1141.515991 -1141.515991 -11802.683112   \n",
       "78765  17 -1141.515991 -1141.515991 -1136.589079 -1151.365964 -11802.683112   \n",
       "\n",
       "             TEMP_1        TEMP_2        TEMP_3      ACC1_0  ...      BVP_55  \\\n",
       "0      10279.722091  10279.722091  10279.722091  126.326243  ... -104.371386   \n",
       "1      10279.722091  10279.722091  10279.722091   90.734562  ...   40.556707   \n",
       "2      10279.722091  10279.722091  10279.722091  -27.904372  ...   59.620226   \n",
       "3      10279.722091  10464.748540  10464.748540  -27.904372  ...  -92.892373   \n",
       "4      10464.748540  10464.748540  10464.748540  -39.768266  ...   -6.795332   \n",
       "...             ...           ...           ...         ...  ...         ...   \n",
       "78761 -11802.683112 -11802.683112 -11802.683112   57.652528  ...   13.827887   \n",
       "78762 -11802.683112 -11802.683112 -11802.683112   57.652528  ...  -28.632268   \n",
       "78763 -11802.683112 -11802.683112 -11802.683112   57.652528  ...   12.448817   \n",
       "78764 -11802.683112 -11802.683112 -11412.917628   57.652528  ...   -9.110212   \n",
       "78765 -11412.917628 -11412.917628 -11412.917628   57.652528  ...    4.212357   \n",
       "\n",
       "           BVP_56      BVP_57      BVP_58      BVP_59      BVP_60     BVP_61  \\\n",
       "0     -124.493001 -136.216532 -137.408002 -128.387507 -111.782506 -91.536409   \n",
       "1       36.106477   30.326959   25.850055   23.818332   23.653838  23.849453   \n",
       "2       48.839201   38.658357   31.562887   28.882079   28.415272  27.312718   \n",
       "3      -97.182554  -94.319469  -83.391734  -65.897576  -45.375840 -26.334550   \n",
       "4       -4.105633   -2.803019   -2.358440   -2.225067   -2.042790  -1.833838   \n",
       "...           ...         ...         ...         ...         ...        ...   \n",
       "78761   13.207938   12.701858   12.233733   11.664393   10.917924   9.918415   \n",
       "78762  -26.405514  -23.444943  -20.092160  -16.562248  -12.918468  -9.186125   \n",
       "78763   12.195777   11.816217   11.322788   10.753448   10.146151   9.526202   \n",
       "78764   -7.427495   -5.491737   -3.189070   -0.544800    2.213339   4.908218   \n",
       "78765    3.010416    1.618694    0.125757   -1.379833   -2.860118  -4.340404   \n",
       "\n",
       "          BVP_62     BVP_63  stress  \n",
       "0     -71.450360 -54.013997     0.0  \n",
       "1      23.195923  21.515416     0.0  \n",
       "2      22.711332  13.432982     0.0  \n",
       "3     -12.494826  -5.474934     0.0  \n",
       "4      -1.958320  -2.878597     0.0  \n",
       "...          ...        ...     ...  \n",
       "78761   8.640562   7.097016     0.0  \n",
       "78762  -5.339913  -1.519005     0.0  \n",
       "78763   8.868298   8.045917     0.0  \n",
       "78764   7.350056   9.450290     0.0  \n",
       "78765  -5.833341  -7.402191     0.0  \n",
       "\n",
       "[78766 rows x 170 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/wesad/wesad_dataset.pkl\")\n",
    "df = df[df['stress'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36a5a04-3cba-4661-bb8e-2c7690b0918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    58834\n",
       "1.0    19932\n",
       "Name: stress, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stress'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8683950-153e-454f-8486-9c5e4387e31e",
   "metadata": {},
   "source": [
    "# Generic model\n",
    "each user belongs to either the train or the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d8366b-fa9d-4496-aa2f-1ffcf2d3a424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62784, 168) (62784,) (15982, 168) (15982,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split_per_user(df,target_column='stress')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa797400-396a-4c68-b976-24347491c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy f1 score: 0.7410837191840821\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dummy Classifier for comparison\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train_smote, y_train_smote)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, dummy_predictions, average='micro')\n",
    "print(f'Dummy f1 score: {f1}')\n",
    "plot_confusion_matrix(y_test, dummy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9029e17-4a2f-467b-a29f-bc6cf0391936",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)\n",
    "#clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "#clf = GradientBoostingClassifier(n_estimators=160, learning_rate=0.3, random_state=42)\n",
    "#clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "#clf = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001)\n",
    "#clf = LGBMClassifier(boosting_type='gbdt', n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f9907-bce9-4699-ae09-d29dc1f09375",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_smote, y_train_smote)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"F1 Score: {f1}\")\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f4a33-e9c6-4bf0-b12b-53bde5408b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_scores = clf.predict_proba(X_test)[:, 0]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288d309-2d97-44c4-90b6-574bac5edaae",
   "metadata": {},
   "source": [
    "# Leave one person out (LOPO) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beae0cb3-45dc-405a-888b-042e344e4ccc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     26\u001b[0m X_train_smote, y_train_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     30\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df.drop(['stress', 'id'], axis=1)  # Features\n",
    "y = df['stress']  # Target variable\n",
    "unique_labels = y.unique()\n",
    "groups = df['id']  # Group identifier for LOPO\n",
    "\n",
    "#model = DummyClassifier(strategy='most_frequent')\n",
    "#model = SVC()\n",
    "#model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model = GradientBoostingClassifier(n_estimators=160, learning_rate=0.3, random_state=42)\n",
    "#model = LogisticRegression(random_state=42)\n",
    "#model = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001)\n",
    "#model = LGBMClassifier(boosting_type='gbdt', n_estimators=100)\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y, groups):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    scores.append(score)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Calculate the average performance across all LOPO iterations\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average f1 score across all LOPO iterations: {average_score}')\n",
    "total_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "print(total_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16d634-8360-49b0-94f2-b7d36fe6a9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3630567-1722-4214-9316-56d8a56847df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e8cf2-748e-466a-9faa-91652cff4748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c07d05-4b6a-4a62-ab9a-6fdb21e75362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stress', 'id'], axis=1)  # Features\n",
    "y = df['stress']  # Target variable\n",
    "unique_labels = y.unique()\n",
    "groups = df['id']  # Group identifier for LOPO\n",
    "\n",
    "#model = LogisticRegression(random_state=42)\n",
    "model = LinearDiscriminantAnalysis(\n",
    "    covariance_estimator=None,\n",
    "    n_components=None,\n",
    "    priors=None,\n",
    "    shrinkage=None,\n",
    "    solver='svd',\n",
    "    store_covariance=False,\n",
    "    tol=0.0001\n",
    ")\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "scores = []\n",
    "confusion_matrices = []\n",
    "all_y_pred = []\n",
    "all_y_test = []\n",
    "all_X_test = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    scores.append(score)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # Append the current iteration's data to the lists\n",
    "    all_y_pred.extend(y_pred.tolist())\n",
    "    all_y_test.extend(y_test.tolist())\n",
    "    all_X_test.append(X_test)\n",
    "\n",
    "# Calculate the average performance across all LOPO iterations\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average f1-scores across all LOPO iterations: {average_score}')\n",
    "total_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "print(total_confusion_matrix)\n",
    "\n",
    "# Convert lists and DataFrame pieces to full DataFrames\n",
    "all_y_pred_df = pd.DataFrame(all_y_pred, columns=['category_madrs'])\n",
    "all_y_test_df = pd.DataFrame(all_y_test, columns=['category_madrs'])\n",
    "all_X_test_df = pd.concat(all_X_test).reset_index(drop=True)\n",
    "\n",
    "# Saving the DataFrames to CSV files\n",
    "all_y_test_df.to_csv('../data/wesad/predictions/depresjon_y_test_LOPO.csv', index=False)\n",
    "all_y_pred_df.to_csv('../data/wesad/predictions/depresjon_y_pred_LOPO.csv', index=False)\n",
    "all_X_test_df.to_csv('../data/wesad/predictions/depresjon_X_test_LOPO.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
