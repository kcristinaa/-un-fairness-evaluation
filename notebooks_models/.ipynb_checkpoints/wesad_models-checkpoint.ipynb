{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fa9998-ac9a-4f8d-ae05-3684e32db8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d3758dd-6133-4d12-8973-78a429f2df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_per_user(data, train_size=0.8, target_column='stress'):\n",
    "    users = list(set(data.id))\n",
    "    users = sorted(users, reverse=True)\n",
    "    total_users = len(users)\n",
    "    slice_idx = int(train_size * total_users)\n",
    "    users_train = users[:slice_idx]\n",
    "    users_test = users[slice_idx:]\n",
    "\n",
    "    # Split data based on user IDs\n",
    "    train_data = data[data.id.isin(users_train)]\n",
    "    test_data = data[data.id.isin(users_test)]\n",
    "\n",
    "    x_train = train_data.drop(['id', target_column], axis=1)\n",
    "    y_train = train_data[target_column]\n",
    "    x_test = test_data.drop(['id', target_column], axis=1)\n",
    "    y_test = test_data[target_column]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c4ad6a-bdd8-4eb2-a69a-575964397cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33106f20-f77c-4387-8758-25d084a37859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EDA_0</th>\n",
       "      <th>EDA_1</th>\n",
       "      <th>EDA_2</th>\n",
       "      <th>EDA_3</th>\n",
       "      <th>TEMP_0</th>\n",
       "      <th>TEMP_1</th>\n",
       "      <th>TEMP_2</th>\n",
       "      <th>TEMP_3</th>\n",
       "      <th>ACC1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>BVP_55</th>\n",
       "      <th>BVP_56</th>\n",
       "      <th>BVP_57</th>\n",
       "      <th>BVP_58</th>\n",
       "      <th>BVP_59</th>\n",
       "      <th>BVP_60</th>\n",
       "      <th>BVP_61</th>\n",
       "      <th>BVP_62</th>\n",
       "      <th>BVP_63</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5452.450365</td>\n",
       "      <td>5366.846848</td>\n",
       "      <td>5264.122627</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>126.326243</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.371386</td>\n",
       "      <td>-124.493001</td>\n",
       "      <td>-136.216532</td>\n",
       "      <td>-137.408002</td>\n",
       "      <td>-128.387507</td>\n",
       "      <td>-111.782506</td>\n",
       "      <td>-91.536409</td>\n",
       "      <td>-71.450360</td>\n",
       "      <td>-54.013997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5264.122627</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>5127.156998</td>\n",
       "      <td>5013.021944</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>90.734562</td>\n",
       "      <td>...</td>\n",
       "      <td>40.556707</td>\n",
       "      <td>36.106477</td>\n",
       "      <td>30.326959</td>\n",
       "      <td>25.850055</td>\n",
       "      <td>23.818332</td>\n",
       "      <td>23.653838</td>\n",
       "      <td>23.849453</td>\n",
       "      <td>23.195923</td>\n",
       "      <td>21.515416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5127.156998</td>\n",
       "      <td>5013.021944</td>\n",
       "      <td>5372.556718</td>\n",
       "      <td>5235.591090</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>-27.904372</td>\n",
       "      <td>...</td>\n",
       "      <td>59.620226</td>\n",
       "      <td>48.839201</td>\n",
       "      <td>38.658357</td>\n",
       "      <td>31.562887</td>\n",
       "      <td>28.882079</td>\n",
       "      <td>28.415272</td>\n",
       "      <td>27.312718</td>\n",
       "      <td>22.711332</td>\n",
       "      <td>13.432982</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5372.556718</td>\n",
       "      <td>5235.591090</td>\n",
       "      <td>5184.228979</td>\n",
       "      <td>5155.692989</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10279.722091</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>-27.904372</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.892373</td>\n",
       "      <td>-97.182554</td>\n",
       "      <td>-94.319469</td>\n",
       "      <td>-83.391734</td>\n",
       "      <td>-65.897576</td>\n",
       "      <td>-45.375840</td>\n",
       "      <td>-26.334550</td>\n",
       "      <td>-12.494826</td>\n",
       "      <td>-5.474934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5184.228979</td>\n",
       "      <td>5155.692989</td>\n",
       "      <td>5115.746165</td>\n",
       "      <td>5081.504758</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>10464.748540</td>\n",
       "      <td>-39.768266</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.795332</td>\n",
       "      <td>-4.105633</td>\n",
       "      <td>-2.803019</td>\n",
       "      <td>-2.358440</td>\n",
       "      <td>-2.225067</td>\n",
       "      <td>-2.042790</td>\n",
       "      <td>-1.833838</td>\n",
       "      <td>-1.958320</td>\n",
       "      <td>-2.878597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78761</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1146.439053</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>13.827887</td>\n",
       "      <td>13.207938</td>\n",
       "      <td>12.701858</td>\n",
       "      <td>12.233733</td>\n",
       "      <td>11.664393</td>\n",
       "      <td>10.917924</td>\n",
       "      <td>9.918415</td>\n",
       "      <td>8.640562</td>\n",
       "      <td>7.097016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78762</th>\n",
       "      <td>17</td>\n",
       "      <td>-1146.439053</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.632268</td>\n",
       "      <td>-26.405514</td>\n",
       "      <td>-23.444943</td>\n",
       "      <td>-20.092160</td>\n",
       "      <td>-16.562248</td>\n",
       "      <td>-12.918468</td>\n",
       "      <td>-9.186125</td>\n",
       "      <td>-5.339913</td>\n",
       "      <td>-1.519005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78763</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448817</td>\n",
       "      <td>12.195777</td>\n",
       "      <td>11.816217</td>\n",
       "      <td>11.322788</td>\n",
       "      <td>10.753448</td>\n",
       "      <td>10.146151</td>\n",
       "      <td>9.526202</td>\n",
       "      <td>8.868298</td>\n",
       "      <td>8.045917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78764</th>\n",
       "      <td>17</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.110212</td>\n",
       "      <td>-7.427495</td>\n",
       "      <td>-5.491737</td>\n",
       "      <td>-3.189070</td>\n",
       "      <td>-0.544800</td>\n",
       "      <td>2.213339</td>\n",
       "      <td>4.908218</td>\n",
       "      <td>7.350056</td>\n",
       "      <td>9.450290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78765</th>\n",
       "      <td>17</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1141.515991</td>\n",
       "      <td>-1136.589079</td>\n",
       "      <td>-1151.365964</td>\n",
       "      <td>-11802.683112</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>-11412.917628</td>\n",
       "      <td>57.652528</td>\n",
       "      <td>...</td>\n",
       "      <td>4.212357</td>\n",
       "      <td>3.010416</td>\n",
       "      <td>1.618694</td>\n",
       "      <td>0.125757</td>\n",
       "      <td>-1.379833</td>\n",
       "      <td>-2.860118</td>\n",
       "      <td>-4.340404</td>\n",
       "      <td>-5.833341</td>\n",
       "      <td>-7.402191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78766 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        EDA_0        EDA_1        EDA_2        EDA_3        TEMP_0  \\\n",
       "0       2  5452.450365  5366.846848  5264.122627  5115.746165  10279.722091   \n",
       "1       2  5264.122627  5115.746165  5127.156998  5013.021944  10279.722091   \n",
       "2       2  5127.156998  5013.021944  5372.556718  5235.591090  10279.722091   \n",
       "3       2  5372.556718  5235.591090  5184.228979  5155.692989  10279.722091   \n",
       "4       2  5184.228979  5155.692989  5115.746165  5081.504758  10464.748540   \n",
       "...    ..          ...          ...          ...          ...           ...   \n",
       "78761  17 -1141.515991 -1141.515991 -1146.439053 -1141.515991 -11412.917628   \n",
       "78762  17 -1146.439053 -1141.515991 -1141.515991 -1141.515991 -11802.683112   \n",
       "78763  17 -1141.515991 -1141.515991 -1136.589079 -1151.365964 -11802.683112   \n",
       "78764  17 -1136.589079 -1151.365964 -1141.515991 -1141.515991 -11802.683112   \n",
       "78765  17 -1141.515991 -1141.515991 -1136.589079 -1151.365964 -11802.683112   \n",
       "\n",
       "             TEMP_1        TEMP_2        TEMP_3      ACC1_0  ...      BVP_55  \\\n",
       "0      10279.722091  10279.722091  10279.722091  126.326243  ... -104.371386   \n",
       "1      10279.722091  10279.722091  10279.722091   90.734562  ...   40.556707   \n",
       "2      10279.722091  10279.722091  10279.722091  -27.904372  ...   59.620226   \n",
       "3      10279.722091  10464.748540  10464.748540  -27.904372  ...  -92.892373   \n",
       "4      10464.748540  10464.748540  10464.748540  -39.768266  ...   -6.795332   \n",
       "...             ...           ...           ...         ...  ...         ...   \n",
       "78761 -11802.683112 -11802.683112 -11802.683112   57.652528  ...   13.827887   \n",
       "78762 -11802.683112 -11802.683112 -11802.683112   57.652528  ...  -28.632268   \n",
       "78763 -11802.683112 -11802.683112 -11802.683112   57.652528  ...   12.448817   \n",
       "78764 -11802.683112 -11802.683112 -11412.917628   57.652528  ...   -9.110212   \n",
       "78765 -11412.917628 -11412.917628 -11412.917628   57.652528  ...    4.212357   \n",
       "\n",
       "           BVP_56      BVP_57      BVP_58      BVP_59      BVP_60     BVP_61  \\\n",
       "0     -124.493001 -136.216532 -137.408002 -128.387507 -111.782506 -91.536409   \n",
       "1       36.106477   30.326959   25.850055   23.818332   23.653838  23.849453   \n",
       "2       48.839201   38.658357   31.562887   28.882079   28.415272  27.312718   \n",
       "3      -97.182554  -94.319469  -83.391734  -65.897576  -45.375840 -26.334550   \n",
       "4       -4.105633   -2.803019   -2.358440   -2.225067   -2.042790  -1.833838   \n",
       "...           ...         ...         ...         ...         ...        ...   \n",
       "78761   13.207938   12.701858   12.233733   11.664393   10.917924   9.918415   \n",
       "78762  -26.405514  -23.444943  -20.092160  -16.562248  -12.918468  -9.186125   \n",
       "78763   12.195777   11.816217   11.322788   10.753448   10.146151   9.526202   \n",
       "78764   -7.427495   -5.491737   -3.189070   -0.544800    2.213339   4.908218   \n",
       "78765    3.010416    1.618694    0.125757   -1.379833   -2.860118  -4.340404   \n",
       "\n",
       "          BVP_62     BVP_63  stress  \n",
       "0     -71.450360 -54.013997     0.0  \n",
       "1      23.195923  21.515416     0.0  \n",
       "2      22.711332  13.432982     0.0  \n",
       "3     -12.494826  -5.474934     0.0  \n",
       "4      -1.958320  -2.878597     0.0  \n",
       "...          ...        ...     ...  \n",
       "78761   8.640562   7.097016     0.0  \n",
       "78762  -5.339913  -1.519005     0.0  \n",
       "78763   8.868298   8.045917     0.0  \n",
       "78764   7.350056   9.450290     0.0  \n",
       "78765  -5.833341  -7.402191     0.0  \n",
       "\n",
       "[78766 rows x 170 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/wesad/wesad_dataset.pkl\")\n",
    "df = df[df['stress'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36a5a04-3cba-4661-bb8e-2c7690b0918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    58834\n",
       "1.0    19932\n",
       "Name: stress, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stress'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8683950-153e-454f-8486-9c5e4387e31e",
   "metadata": {},
   "source": [
    "# Generic model\n",
    "each user belongs to either the train or the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8366b-fa9d-4496-aa2f-1ffcf2d3a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split_per_user(df,target_column='stress')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa797400-396a-4c68-b976-24347491c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier for comparison\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train_smote, y_train_smote)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, dummy_predictions, average='micro')\n",
    "print(f'Dummy f1 score: {f1}')\n",
    "plot_confusion_matrix(y_test, dummy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9029e17-4a2f-467b-a29f-bc6cf0391936",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)\n",
    "#clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "#clf = GradientBoostingClassifier(n_estimators=160, learning_rate=0.3, random_state=42)\n",
    "#clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "#clf = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001)\n",
    "#clf = LGBMClassifier(boosting_type='gbdt', n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f9907-bce9-4699-ae09-d29dc1f09375",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_smote, y_train_smote)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"F1 Score: {f1}\")\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f4a33-e9c6-4bf0-b12b-53bde5408b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_scores = clf.predict_proba(X_test)[:, 0]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288d309-2d97-44c4-90b6-574bac5edaae",
   "metadata": {},
   "source": [
    "# Leave one person out (LOPO) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beae0cb3-45dc-405a-888b-042e344e4ccc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     26\u001b[0m X_train_smote, y_train_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     30\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\un-fairness\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df.drop(['stress', 'id'], axis=1)  # Features\n",
    "y = df['stress']  # Target variable\n",
    "unique_labels = y.unique()\n",
    "groups = df['id']  # Group identifier for LOPO\n",
    "\n",
    "#model = DummyClassifier(strategy='most_frequent')\n",
    "#model = SVC()\n",
    "#model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model = GradientBoostingClassifier(n_estimators=160, learning_rate=0.3, random_state=42)\n",
    "#model = LogisticRegression(random_state=42)\n",
    "#model = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001)\n",
    "#model = LGBMClassifier(boosting_type='gbdt', n_estimators=100)\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y, groups):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    scores.append(score)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "# Calculate the average performance across all LOPO iterations\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average f1 score across all LOPO iterations: {average_score}')\n",
    "total_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "print(total_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16d634-8360-49b0-94f2-b7d36fe6a9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3630567-1722-4214-9316-56d8a56847df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e8cf2-748e-466a-9faa-91652cff4748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c07d05-4b6a-4a62-ab9a-6fdb21e75362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['stress', 'id'], axis=1)  # Features\n",
    "y = df['stress']  # Target variable\n",
    "unique_labels = y.unique()\n",
    "groups = df['id']  # Group identifier for LOPO\n",
    "\n",
    "#model = LogisticRegression(random_state=42)\n",
    "model = LinearDiscriminantAnalysis(\n",
    "    covariance_estimator=None,\n",
    "    n_components=None,\n",
    "    priors=None,\n",
    "    shrinkage=None,\n",
    "    solver='svd',\n",
    "    store_covariance=False,\n",
    "    tol=0.0001\n",
    ")\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "scores = []\n",
    "confusion_matrices = []\n",
    "all_y_pred = []\n",
    "all_y_test = []\n",
    "all_X_test = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='micro')\n",
    "    scores.append(score)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # Append the current iteration's data to the lists\n",
    "    all_y_pred.extend(y_pred.tolist())\n",
    "    all_y_test.extend(y_test.tolist())\n",
    "    all_X_test.append(X_test)\n",
    "\n",
    "# Calculate the average performance across all LOPO iterations\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average f1-scores across all LOPO iterations: {average_score}')\n",
    "total_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "print(total_confusion_matrix)\n",
    "\n",
    "# Convert lists and DataFrame pieces to full DataFrames\n",
    "all_y_pred_df = pd.DataFrame(all_y_pred, columns=['category_madrs'])\n",
    "all_y_test_df = pd.DataFrame(all_y_test, columns=['category_madrs'])\n",
    "all_X_test_df = pd.concat(all_X_test).reset_index(drop=True)\n",
    "\n",
    "# Saving the DataFrames to CSV files\n",
    "all_y_test_df.to_csv('../data/wesad/predictions/depresjon_y_test_LOPO.csv', index=False)\n",
    "all_y_pred_df.to_csv('../data/wesad/predictions/depresjon_y_pred_LOPO.csv', index=False)\n",
    "all_X_test_df.to_csv('../data/wesad/predictions/depresjon_X_test_LOPO.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
